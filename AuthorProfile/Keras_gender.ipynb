{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(text, stop=False):\n",
    "    raw_text =  re.split(' ',text)\n",
    "    unwanted = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~Â£'\n",
    "    raw_text2 = ''\n",
    "    for k in raw_text:\n",
    "        # Ignore urls\n",
    "        if k.startswith('http') or k.startswith('http'):\n",
    "            continue\n",
    "        elif k.startswith('@'):     \n",
    "            continue\n",
    "        elif k.startswith('#'):\n",
    "            continue\n",
    "        else:\n",
    "            raw_text2 += ' '\n",
    "            raw_text2 += k\n",
    "    words_raw = nltk.word_tokenize(raw_text2.lower())\n",
    "    words = [w for w in words_raw if w not in unwanted]\n",
    "    if stop: \n",
    "        words = [w for w in words if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 264 ms, total: 21.7 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'blog-gender-dataset.xlsx'\n",
    "\n",
    "workbook = xlrd.open_workbook(path)\n",
    "worksheet = workbook.sheet_by_index(0)\n",
    "\n",
    "# Change this depending on how many header rows are present\n",
    "# Set to 0 if you want to include the header data.\n",
    "offset = 0\n",
    "\n",
    "rows = []\n",
    "for i, row in enumerate(range(worksheet.nrows)):\n",
    "    if i <= offset:  # (Optionally) skip headers\n",
    "        continue\n",
    "    r = []\n",
    "    for j, col in enumerate(range(worksheet.ncols)):\n",
    "        r.append(worksheet.cell_value(i, j))\n",
    "    rows.append(r[:2])\n",
    "    \n",
    "x_raw = []\n",
    "y = []\n",
    "\n",
    "for i in rows:\n",
    "    x_raw.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 4 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dict = {}\n",
    "\n",
    "for sent in x_raw:\n",
    "    for word in get_words(sent):\n",
    "        if word not in model_dict.keys():\n",
    "            model_dict[word] = 1\n",
    "        else:\n",
    "            model_dict[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66259\n"
     ]
    }
   ],
   "source": [
    "top_words = len(model_dict)+1\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 52 ms, total: 12.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t1 = sorted(model_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "up_prunung = 200\n",
    "down_pruning = 50000\n",
    "x_encoded = []\n",
    "encoding = {}\n",
    "x_id = 0\n",
    "for term in t1[up_prunung:down_pruning]:\n",
    "    encoding[term[0]] = x_id\n",
    "    x_id+=1\n",
    "\n",
    "for sent in x_raw:\n",
    "    words = []\n",
    "    for word in get_words(sent):\n",
    "        if word in encoding.keys():\n",
    "            words.append(encoding[word])\n",
    "    x_encoded.append(words)\n",
    "top_words = down_pruning - up_prunung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49800\n"
     ]
    }
   ],
   "source": [
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idx = list(range(len(rows)))\n",
    "shuffle(idx)\n",
    "stamp = int(0.8*len(idx))\n",
    "\n",
    "x_rand = []\n",
    "y_rand = []\n",
    "for i in idx:\n",
    "    x_rand.append(x_encoded[i])\n",
    "    y_rand.append(y[i])\n",
    "\n",
    "split_stamp = int(0.8 * len(x_rand))  \n",
    "x_train = x_rand[:split_stamp]\n",
    "y_train = y_rand[:split_stamp]\n",
    "\n",
    "x_test = x_rand[split_stamp:]\n",
    "y_test = y_rand[split_stamp:]\n",
    "\n",
    "\n",
    "y_train_norm = []\n",
    "for i in range(len(y_train)):\n",
    "    if 'F' in y_train[i]:\n",
    "        y_train_norm.append(0)\n",
    "    else:\n",
    "        y_train_norm.append(1)\n",
    "        \n",
    "y_test_norm = []\n",
    "for i in range(len(y_test)):\n",
    "    if 'F' in y_test[i]:\n",
    "        y_test_norm.append(0)\n",
    "    else:\n",
    "        y_test_norm.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49800\n"
     ]
    }
   ],
   "source": [
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 16 ms, total: 84 ms\n",
      "Wall time: 83.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_review_length = 350\n",
    "X_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(x_test, maxlen=max_review_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 350, 128)      6374400     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 350, 40)       25640       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 175, 40)       0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 200)           192800      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             201         lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 6593041\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "CPU times: user 1.34 s, sys: 6.74 s, total: 8.07 s\n",
      "Wall time: 619 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the model\n",
    "embedding_vecor_length = 128 # vary length\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Convolution1D(nb_filter=40, filter_length=5, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2584/2584 [==============================] - 1215s - loss: 0.6938 - acc: 0.5163   \n",
      "Epoch 2/5\n",
      "2584/2584 [==============================] - 1212s - loss: 0.6707 - acc: 0.6115   \n",
      "Epoch 3/5\n",
      "2584/2584 [==============================] - 1217s - loss: 0.3828 - acc: 0.9241   \n",
      "Epoch 4/5\n",
      "2584/2584 [==============================] - 1208s - loss: 0.0538 - acc: 0.9837   \n",
      "Epoch 5/5\n",
      "2584/2584 [==============================] - 1241s - loss: 0.0127 - acc: 0.9965   \n",
      "CPU times: user 2h 25min 8s, sys: 7h 29min 47s, total: 9h 54min 56s\n",
      "Wall time: 1h 41min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe635f917f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train_norm, nb_epoch=5, batch_size=128)\n",
    "# Final evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 84s    \n",
      "Accuracy: 66.77%\n",
      "CPU times: user 1min 31s, sys: 1min 1s, total: 2min 32s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = model.evaluate(X_test, y_test_norm, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
