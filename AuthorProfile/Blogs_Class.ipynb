{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'blogs/'\n",
    "files_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(mypath+files_names[1])\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 432 ms, total: 1.68 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_posts = []\n",
    "labels = []\n",
    "\n",
    "for f in files_names:\n",
    "\n",
    "    data = {}\n",
    "    tags = {}\n",
    "\n",
    "\n",
    "    if 'fe' in f:\n",
    "        tags['gender'] = 0\n",
    "    else:\n",
    "        tags['gender'] = 1\n",
    "\n",
    "    tags['age']=int(f.split('.')[2])\n",
    "    tags['field']=(f.split('.')[3])\n",
    "    tags['zodiac']=(f.split('.')[4])\n",
    "\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == 'date':\n",
    "            data['date'] = child.text\n",
    "        elif child.tag == 'post':\n",
    "            data['text'] = child.text\n",
    "            raw_posts.append(data)\n",
    "            labels.append(tags)\n",
    "            data = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words(text, stop=False):\n",
    "    raw_text =  re.split(' ',text)\n",
    "    unwanted = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~Â£\\n'\n",
    "    raw_text2 = ''\n",
    "    for k in raw_text:\n",
    "        # Ignore urls\n",
    "        if k.startswith('http') or k.startswith('http'):\n",
    "            continue\n",
    "        elif k.startswith('@'):     \n",
    "            continue\n",
    "        elif k.startswith('#'):\n",
    "            continue\n",
    "        else:\n",
    "            raw_text2 += ' '\n",
    "            raw_text2 += k\n",
    "    words_raw = nltk.word_tokenize(raw_text2.lower())\n",
    "    words = [w for w in words_raw if w not in unwanted]\n",
    "    if stop: \n",
    "        words = [w for w in words if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 408 ms, sys: 48 ms, total: 456 ms\n",
      "Wall time: 455 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = []\n",
    "for item in labels:\n",
    "    if item['age'] < 18:\n",
    "        y.append(0)\n",
    "    elif item['age'] < 28:\n",
    "        y.append(1)\n",
    "    else: \n",
    "        y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 264 ms, sys: 0 ns, total: 264 ms\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_gen = []\n",
    "for item in labels:\n",
    "    y_gen.append(item['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 776 ms, sys: 384 ms, total: 1.16 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_raw = []\n",
    "for item in raw_posts:\n",
    "    x_raw.append(raw_posts[0]['date']+raw_posts[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendim models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument, TaggedLineDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, prefix, sources):\n",
    "        self.sources = sources\n",
    "        self.prefix = prefix\n",
    "        k1 = self.to_array()\n",
    "        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item_no, line in enumerate(self.sources):\n",
    "            yield LabeledSentence(get_words(line), [self.prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for item_no, line in enumerate(self.sources):\n",
    "            self.sentences.append(LabeledSentence(get_words(line), [self.prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 0 ns, total: 2.31 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split = 1000*1000\n",
    "idx = list(range(len(x_raw))) \n",
    "shuffle(idx)\n",
    "\n",
    "x_rand = []\n",
    "y_rand = []\n",
    "for i in idx[:split]:\n",
    "    x_rand.append(x_raw[i])\n",
    "    y_rand.append(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 0 ns, total: 1min 52s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = LabeledLineSentence('age', x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 0 ns, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Doc2Vec(min_count=1, window=6, size=255, sample=1e-4, negative=5, workers=20)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Epoch  1\n",
      "Epoch  2\n",
      "Epoch  3\n",
      "Epoch  4\n",
      "Epoch  5\n",
      "Epoch  6\n",
      "Epoch  7\n",
      "Epoch  8\n",
      "Epoch  9\n",
      "CPU times: user 28min 14s, sys: 5min 52s, total: 34min 7s\n",
      "Wall time: 19min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch \", epoch)\n",
    "    model.train(sentences.sentences_perm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 0 ns, total: 208 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idx = list(range(len(x_rand))) \n",
    "\n",
    "x_rand_norm = []\n",
    "\n",
    "for i in idx:\n",
    "    x_rand_norm.append(model.docvecs['age_{}'.format(i)])\n",
    "\n",
    "\n",
    "split_stamp = int(0.8 * len(x_rand_norm))  \n",
    "x_train = x_rand_norm[:split_stamp]\n",
    "y_train = y_rand[:split_stamp]\n",
    "\n",
    "x_test = x_rand_norm[split_stamp:]\n",
    "y_test = y_rand[split_stamp:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bulat/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/bulat/.local/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'degree': 3}\n",
      "\n",
      "Best score: 0.427\n",
      "Test score\n",
      "0.4293\n",
      "CPU times: user 1h 2min 7s, sys: 3.36 s, total: 1h 2min 10s\n",
      "Wall time: 1h 37min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC()\n",
    "parameters = {\n",
    "    'degree':[3,4,5]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(svm, parameters, cv=3, n_jobs=20)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "\n",
    "print(\"Test score\")\n",
    "print(clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 4 ms, total: 300 ms\n",
      "Wall time: 297 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_gen = []\n",
    "for item in labels:\n",
    "    y_gen.append(item['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 0 ns, total: 1.61 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split = 100*1000\n",
    "idx = list(range(len(x_raw))) \n",
    "shuffle(idx)\n",
    "\n",
    "x_rand = []\n",
    "y_rand = []\n",
    "for i in idx[:split]:\n",
    "    x_rand.append(x_raw[i])\n",
    "    y_rand.append(y_gen[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Epoch  1\n",
      "Epoch  2\n",
      "Epoch  3\n",
      "Epoch  4\n",
      "Epoch  5\n",
      "Epoch  6\n",
      "Epoch  7\n",
      "Epoch  8\n",
      "Epoch  9\n",
      "Epoch  10\n",
      "Epoch  11\n",
      "Epoch  12\n",
      "Epoch  13\n",
      "Epoch  14\n",
      "Epoch  15\n",
      "Epoch  16\n",
      "Epoch  17\n",
      "Epoch  18\n",
      "Epoch  19\n",
      "Epoch  20\n",
      "Epoch  21\n",
      "Epoch  22\n",
      "Epoch  23\n",
      "Epoch  24\n",
      "Epoch  25\n",
      "Epoch  26\n",
      "Epoch  27\n",
      "Epoch  28\n",
      "Epoch  29\n",
      "CPU times: user 28min 4s, sys: 5min 11s, total: 33min 15s\n",
      "Wall time: 18min 57s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = LabeledLineSentence('age', x_rand)\n",
    "\n",
    "\n",
    "\n",
    "model = Doc2Vec(min_count=1, window=8, size=350, sample=1e-4, negative=5, workers=20)\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(\"Epoch \", epoch)\n",
    "    model.train(sentences.sentences_perm())\n",
    "    \n",
    "\n",
    "idx = list(range(len(x_rand))) \n",
    "\n",
    "x_rand_norm = []\n",
    "\n",
    "for i in idx:\n",
    "    x_rand_norm.append(model.docvecs['age_{}'.format(i)])\n",
    "\n",
    "\n",
    "split_stamp = int(0.8 * len(x_rand_norm))  \n",
    "x_train = x_rand_norm[:split_stamp]\n",
    "y_train = y_rand[:split_stamp]\n",
    "\n",
    "x_test = x_rand_norm[split_stamp:]\n",
    "y_test = y_rand[split_stamp:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'degree': 3}\n",
      "\n",
      "Best score: 0.503\n",
      "Test score\n",
      "0.498\n",
      "CPU times: user 33.8 s, sys: 940 ms, total: 34.8 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC()\n",
    "parameters = {\n",
    "    'degree':[3,4,5]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(svm, parameters, cv=3, n_jobs=20)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "\n",
    "print(\"Test score\")\n",
    "print(clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score\n",
      "0.497666666667\n",
      "CPU times: user 5min 40s, sys: 0 ns, total: 5min 40s\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC()\n",
    "parameters = {\n",
    "    'degree':[3,4,5]\n",
    "}\n",
    "\n",
    "#clf = GridSearchCV(svm, parameters, cv=3, n_jobs=20)\n",
    "#clf.fit(x_train, y_train)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print(\"Test score\")\n",
    "print(svm.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer='word', ngram_range=(1,3), stop_words='english')),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('nb', SVC()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_stamp = int(0.8 * len(x_rand))  \n",
    "x_train = x_rand[:split_stamp]\n",
    "y_train = y_rand[:split_stamp]\n",
    "\n",
    "x_test = x_rand[split_stamp:]\n",
    "y_test = y_rand[split_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 16s, sys: 0 ns, total: 35min 16s\n",
      "Wall time: 35min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        s...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 29s, sys: 0 ns, total: 6min 29s\n",
      "Wall time: 6min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49590000000000001"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
